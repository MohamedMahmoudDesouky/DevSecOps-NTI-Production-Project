# azure-pipelines-infra.yml
# Full DevSecOps Pipeline for Infrastructure & Governance

trigger:
  branches:
    include:
      - main
  paths:
    include:
      - terraform/*
      - k8s/kyverno/*
      - ansible/*

variables:
  - group: "aws-credentials"

  - name: awsRegion
    value: "us-east-2"
  - name: clusterName
    value: "capstone-project"

  # Backend settings (kept as variables so theyâ€™re easy to change)
  - name: tfStateBucket
    value: "capstone-tf-state-1770945563"
  - name: tfStateKey
    value: "final-project/terraform.tfstate"
  - name: tfLockTable
    value: "terraform-lock"

stages:
  # ==========================================
  # Stage 1: IaC Security & Provisioning
  # ==========================================
  - stage: Infrastructure
    displayName: "Terraform & IaC Security"
    jobs:
      - job: Terraform_Plan_Apply
        displayName: "SCA, Plan & Apply"
        pool:
          name: Default
        steps:
          # ------------------------------
          # IaC Security Scan (Trivy)
          # ------------------------------
          - script: |
              set -euxo pipefail
              mkdir -p ~/bin
              export PATH="$PATH:~/bin"

              if ! command -v trivy &> /dev/null; then
                echo "Trivy not found in path, downloading to ~/bin..."
                wget -q https://github.com/aquasecurity/trivy/releases/download/v0.49.1/trivy_0.49.1_Linux-64bit.tar.gz
                tar zxvf trivy_0.49.1_Linux-64bit.tar.gz -C ~/bin/ trivy
                rm trivy_0.49.1_Linux-64bit.tar.gz
              fi

              trivy version
              trivy config terraform/
            displayName: "IaC Security Scan (Trivy)"

          # ------------------------------
          # Diagnostics + Backend checks + Init
          # ------------------------------
          - script: |
              set -euxo pipefail

              # Install AWS CLI if missing
              if ! command -v aws &> /dev/null; then
                  echo "AWS CLI not found. Installing..."
                  sudo apt-get update
                  sudo apt-get install -y awscli
              fi

              echo "== Repo diagnostics =="
              git log -1 --oneline || true
              df -h || true
              ls -la || true
              ls -la modules/logging/ || true
              test -f modules/logging/main.tf && sed -n '1,200p' modules/logging/main.tf || true
              test -f backend.tf && sed -n '1,200p' backend.tf || true

              echo "== Remote backend diagnostics (S3 + DynamoDB) =="
              aws --version
              aws s3api head-object \
                --bucket "$(tfStateBucket)" \
                --key "$(tfStateKey)" \
                --region "$(awsRegion)" || true

              # aws dynamodb scan \
              #   --table-name "$(tfLockTable)" \
              #   --region "$(awsRegion)" \
              #   --max-items 50 || true

              echo "== Clean local terraform cache =="
              rm -rf .terraform .terraform.lock.hcl

              echo "== Terraform init (with retry) =="
              INIT_SUCCESS="false"
              for i in 1 2 3; do
                echo "Attempt $i/3"
                if terraform init -input=false -reconfigure -no-color \
                  -backend-config="bucket=$(tfStateBucket)" \
                  -backend-config="key=$(tfStateKey)" \
                  -backend-config="region=$(awsRegion)"; then
                  INIT_SUCCESS="true"
                  break
                fi
                echo "terraform init failed. Sleeping 20s then retry..."
                sleep 20
              done

              if [ "$INIT_SUCCESS" != "true" ]; then
                echo "##vso[task.logissue type=error]Terraform Init failed after 3 attempts."
                exit 1
              fi
            displayName: "Terraform Init & Exhaustive Diagnostics"
            workingDirectory: "terraform"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          # ------------------------------
          # Validate
          # ------------------------------
          - script: |
              set -euxo pipefail
              terraform validate -no-color
            displayName: "Terraform Validate"
            workingDirectory: "terraform"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          # ------------------------------
          # Plan
          # ------------------------------
          - script: |
              set -euxo pipefail
              terraform plan -input=false -out=tfplan -no-color
            displayName: "Terraform Plan"
            workingDirectory: "terraform"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          # ------------------------------
          # Apply (main only)
          # ------------------------------
          - script: |
              set -euxo pipefail
              terraform apply -input=false -auto-approve tfplan -no-color
            displayName: "Terraform Apply"
            condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
            workingDirectory: "terraform"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

  # ==========================================
  # Stage 2: Governance (Kyverno)
  # ==========================================
  - stage: Governance
    displayName: "Kyverno Policy Enforcement"
    dependsOn: Infrastructure
    jobs:
      - job: Setup_Kyverno
        displayName: "Install Kyverno & Apply Policies"
        pool:
          name: Default
        steps:
          - script: |
              set -euxo pipefail

              echo "== Check kyverno release status =="
              helm -n kyverno status kyverno || true
              helm -n kyverno history kyverno || true

              # Get release status if exists
              status="$(helm -n kyverno status kyverno 2>/dev/null | awk -F': ' '/^STATUS:/{print $2}' || true)"
              echo "Detected STATUS: ${status:-<none>}"

              if [[ "$status" == pending-install || "$status" == pending-upgrade || "$status" == pending-rollback ]]; then
                echo "Release is pending. Attempting rollback to last successful revision..."

                # Find last deployed revision number (if any)
                last_deployed="$(helm -n kyverno history kyverno 2>/dev/null | awk '$3=="deployed"{rev=$1} END{print rev}' || true)"
                if [[ -n "${last_deployed:-}" ]]; then
                  echo "Rolling back to revision: $last_deployed"
                  helm -n kyverno rollback kyverno "$last_deployed" --wait --timeout 15m || true
                else
                  echo "No deployed revision found. Uninstalling stuck release..."
                  helm -n kyverno uninstall kyverno || true
                fi
              fi
            displayName: "Fix Helm pending operation (Kyverno)"

          - script: |
              set -euxo pipefail

              if ! command -v aws &> /dev/null; then
                  sudo apt-get update && sudo apt-get install -y awscli
              fi

              aws eks update-kubeconfig --name "$(clusterName)" --region "$(awsRegion)"
            displayName: "Update Kubeconfig"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          - script: |
              set -euxo pipefail

              echo "== Check if Kyverno is already installed =="

              if helm status kyverno -n kyverno >/dev/null 2>&1; then
                echo "Kyverno already installed. Checking health..."

                kubectl -n kyverno get deploy,po

                # Check if admission controller is ready
                if kubectl -n kyverno rollout status deploy/kyverno-admission-controller --timeout=30s; then
                  echo "Kyverno is healthy. Skipping install."
                  exit 0
                else
                  echo "Kyverno exists but not healthy. Reinstalling..."
                fi
              fi

              echo "== Installing Kyverno =="

              helm repo add kyverno https://kyverno.github.io/kyverno/ || true
              helm repo update

              helm upgrade --install kyverno kyverno/kyverno \
                --version 3.3.4 \
                -n kyverno --create-namespace \
                --set image.tag="v1.12.7" \
                -f k8s/kyverno/kyverno-values.yaml \
                --wait --timeout 8m


              echo "Kyverno installation complete."
            displayName: "Install Kyverno (Only if Missing)"

          - script: |
              set -euxo pipefail
              kubectl apply -f k8s/kyverno/policies/
            displayName: "Apply Kyverno Cluster Policies"

  # ==========================================
  # Stage 3: Secrets Management (Vault)
  # ==========================================
  - stage: Vault_Setup
    displayName: "Vault Integration"
    dependsOn: Infrastructure
    jobs:
      - job: Vault_Injector
        displayName: "Install Vault Agent Injector"
        pool:
          name: Default
        steps:
          - script: |
              set -euxo pipefail

              if ! command -v aws &> /dev/null; then
                  sudo apt-get update && sudo apt-get install -y awscli
              fi

              aws eks update-kubeconfig --name "$(clusterName)" --region "$(awsRegion)"
            displayName: "Update Kubeconfig"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          - script: |
              set -euxo pipefail
              echo "== Dealing with potential Webhook conflicts =="
              kubectl delete mutatingwebhookconfiguration vault-agent-injector-cfg --ignore-not-found
            displayName: "Cleanup Conflicting Webhook"

          - script: |
              set -euxo pipefail
              helm repo add hashicorp https://helm.releases.hashicorp.com
              helm repo update

              # Assuming Vault Public IP is retrieved from TF output or variable
              VAULT_IP=$(aws ec2 describe-instances \
                --filters "Name=tag:Name,Values=vault-instance" \
                --query "Reservations[].Instances[].PublicIpAddress" \
                --output text)

              echo "Vault IP: $VAULT_IP"

              helm upgrade --install vault hashicorp/vault \
                --set "injector.externalVaultAddr=http://$VAULT_IP:8200" \
                -n vault --create-namespace
            displayName: "Install Vault Agent Injector"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

      - job: Vault_Init
        displayName: "Initialize/Reset Vault & Export Token"
        dependsOn: Vault_Injector
        pool:
          name: Default
        steps:
          # 1) Fetch Terraform Outputs (Need Vault IP & DynamoDB Table)
          - script: |
              set -euo pipefail

              if ! command -v aws &> /dev/null; then
                  sudo apt-get update && sudo apt-get install -y awscli
              fi

              cd terraform
              echo "Initializing Terraform..."
              terraform init -input=false -reconfigure -no-color \
                  -backend-config="bucket=$(tfStateBucket)" \
                  -backend-config="key=$(tfStateKey)" \
                  -backend-config="region=$(awsRegion)" >/dev/null

              echo "Fetching outputs..."
              VAULT_IP=$(aws ec2 describe-instances \
                --filters "Name=tag:Name,Values=vault-instance" \
                --query "Reservations[].Instances[].PublicIpAddress" \
                --output text)

              TABLE_NAME=$(terraform output -raw vault_dynamodb_table_name)

              if [ -z "$VAULT_IP" ] || [ "$VAULT_IP" == "None" ]; then
                  echo "##vso[task.logissue type=error]Vault IP not found"
                  exit 1
              fi

              echo "Vault IP: $VAULT_IP"
              echo "DynamoDB Table: $TABLE_NAME"

              echo "##vso[task.setvariable variable=VAULT_IP]$VAULT_IP"
              echo "##vso[task.setvariable variable=VAULT_TABLE]$TABLE_NAME"
            displayName: "Get Vault Details"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          # 2) Check Status & Reset if needed
          - script: |
              set -euo pipefail

              export VAULT_ADDR="http://$(VAULT_IP):8200"

              echo "Checking Vault status at $VAULT_ADDR..."

              # Install jq if missing
              if ! command -v jq &> /dev/null; then
                  sudo apt-get update && sudo apt-get install -y jq || true
              fi

              # Check status
              HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$VAULT_ADDR/v1/sys/health" || true)
              echo "Vault Health HTTP Code: $HTTP_CODE"

              # 200 = Initialized, Unsealed, Active
              # 429 = Initialized, Unsealed, Standby
              # 501 = Not Initialized
              # 503 = Sealed

              INITIALIZED="false"
              if [[ "$HTTP_CODE" == "200" || "$HTTP_CODE" == "429" || "$HTTP_CODE" == "503" ]]; then
                  INITIALIZED="true"
              fi

              echo "Vault Initialized: $INITIALIZED"

              # LOGIC: If initialized, we WIPE to get a new token (User Request)
              # OR we can add a condition. For now, we assume user lost keys and wants a reset.

              if [ "$INITIALIZED" == "true" ]; then
                  echo "Vault is already initialized."
                  echo "WARNING: Resetting Vault (Wiping DynamoDB & Rebooting) to generate new Root Token as requested!"
                  
                  # 1. Wipe DynamoDB
                  echo "Scanning and deleting items from $(VAULT_TABLE)..."
                  # Note: Scan is slow for large tables, but this is a dev/test vault.
                  aws dynamodb scan --table-name "$(VAULT_TABLE)" --attributes-to-get "Path" "Key" \
                      | jq -r '.Items[] | .Path.S + " " + (.Key.S // "")' \
                      | while read -r p k; do
                          KEY_JSON="{\"Path\": {\"S\": \"$p\"}, \"Key\": {\"S\": \"$k\"}}"
                          aws dynamodb delete-item --table-name "$(VAULT_TABLE)" --key "$KEY_JSON"
                      done
                  
                  echo "DynamoDB table wiped."
                  
                  # 2. Reboot Instance to restart Vault service (easiest way without SSH)
                  aws configure set region $(awsRegion)
                  INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=ip-address,Values=$(VAULT_IP)" --query "Reservations[0].Instances[0].InstanceId" --output text)
                  
                  echo "Rebooting Vault Instance ($INSTANCE_ID)..."
                  aws ec2 reboot-instances --instance-ids "$INSTANCE_ID"
                  
                  echo "Waiting for instance to come back..."
                  sleep 60
                  
                  # Wait for Vault to be responsive (501 Not Initialized)
                  echo "Waiting for Vault service..."
                  for i in {1..30}; do
                      HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$VAULT_ADDR/v1/sys/health" || true)
                      if [[ "$HTTP_CODE" == "501" ]]; then
                          echo "Vault is up and uninitialized (501)."
                          break
                      fi
                      echo "Waiting... ($HTTP_CODE)"
                      sleep 10
                  done
              fi

              # 3) Initialize Vault
              echo "Initializing Vault..."
              # Capture output
              INIT_OUTPUT=$(curl -s --request POST --data '{"secret_shares": 1, "secret_threshold": 1}' "$VAULT_ADDR/v1/sys/init")

              # Check if successful
              if echo "$INIT_OUTPUT" | jq -e .root_token > /dev/null; then
                  ROOT_TOKEN=$(echo "$INIT_OUTPUT" | jq -r .root_token)
                  UNSEAL_KEY=$(echo "$INIT_OUTPUT" | jq -r .keys_base64[0])
                  
                  echo ""
                  echo "=================================================================="
                  echo "VAULT INITIALIZED SUCCESSFULLY"
                  echo "=================================================================="
                  echo "ROOT TOKEN: $ROOT_TOKEN"
                  echo "UNSEAL KEY: $UNSEAL_KEY"
                  echo "=================================================================="
                  echo ""
                  echo "##vso[task.setvariable variable=VAULT_ROOT_TOKEN;isOutput=true;issecret=true]$ROOT_TOKEN"
                  
                  # 4) Unseal Vault
                  echo "Unsealing Vault..."
                  curl -s --request POST --data "{\"key\": \"$UNSEAL_KEY\"}" "$VAULT_ADDR/v1/sys/unseal"
                  
              else
                  echo "Vault initialization failed or already initialized."
                  echo "Output: $INIT_OUTPUT"
                  exit 1
              fi

            name: VaultInitTask
            displayName: "Reset, Init & Unseal Vault"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

      - job: Vault_Configure
        displayName: "Configure Vault (Auth, Roles, Secrets)"
        dependsOn: Vault_Init
        variables:
          VAULT_ROOT_TOKEN: $[ dependencies.Vault_Init.outputs['VaultInitTask.VAULT_ROOT_TOKEN'] ]
        pool:
          name: Default

        steps:
          # 1) Install Ansible
          - script: |
              set -euo pipefail
              if ! command -v ansible-playbook &> /dev/null; then
                  echo "Ansible not found. Installing via pip..."
                  python3 -m pip install --user ansible
                  echo "##vso[task.prependpath]$HOME/.local/bin"
              else
                  echo "Ansible is already installed."
              fi

              # Add ~/.local/bin to PATH for this script execution too
              export PATH="$HOME/.local/bin:$PATH"
              ansible-playbook --version
            displayName: "Install Ansible"

          # 2) Fetch Terraform Outputs (We need cluster info + DB creds)
          - script: |
              set -euo pipefail

              # Terraform Init to read state
              cd terraform
              echo "Initializing Terraform to read state..."
              terraform init -input=false -reconfigure -no-color \
                  -backend-config="bucket=$(tfStateBucket)" \
                  -backend-config="key=$(tfStateKey)" \
                  -backend-config="region=$(awsRegion)" >/dev/null

              # Get all needed outputs
              echo "Fetching Terraform outputs..."

              CLUSTER_NAME=$(terraform output -raw cluster_name)
              RDS_ENDPOINT=$(terraform output -raw rds_endpoint)
              REDIS_ENDPOINT=$(terraform output -raw redis_endpoint)
              DB_PASSWORD=$(terraform output -raw db_password)
              OIDC_ISSUER=$(terraform output -raw cluster_oidc_issuer_url)

              # Export them for next steps (using Azure DevOps variables)
              echo "##vso[task.setvariable variable=TF_CLUSTER_NAME]$CLUSTER_NAME"
              echo "##vso[task.setvariable variable=TF_RDS_ENDPOINT]$RDS_ENDPOINT"
              echo "##vso[task.setvariable variable=TF_REDIS_ENDPOINT]$REDIS_ENDPOINT"
              echo "##vso[task.setvariable variable=TF_DB_PASSWORD;issecret=true]$DB_PASSWORD"
              echo "##vso[task.setvariable variable=TF_OIDC_ISSUER]$OIDC_ISSUER"

              echo "Terraform outputs fetched successfully."
            displayName: "Fetch Terraform Outputs"
            env:
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(awsRegion)

          # 3) Get Vault Public IP (from AWS) + Service Account Token
          - script: |
              set -euo pipefail

              if ! command -v aws &> /dev/null; then
                  sudo apt-get update && sudo apt-get install -y awscli
              fi

              # Configure AWS
              aws configure set aws_access_key_id $(AWS_ACCESS_KEY_ID)
              aws configure set aws_secret_access_key $(AWS_SECRET_ACCESS_KEY)
              aws configure set region $(awsRegion)

              # Update Kubeconfig
              aws eks update-kubeconfig --name "$(TF_CLUSTER_NAME)" --region "$(awsRegion)"

              # Get Vault IP
              echo "Fetching Vault Public IP..."
              VAULT_IP=$(aws ec2 describe-instances \
                --filters "Name=tag:Name,Values=vault-instance" \
                --query "Reservations[].Instances[].PublicIpAddress" \
                --output text)

              if [ -z "$VAULT_IP" ] || [ "$VAULT_IP" == "None" ]; then
                  echo "##vso[task.logissue type=error]Could not find Vault Instance Public IP"
                  exit 1
              fi
              echo "Vault IP: $VAULT_IP"
              echo "##vso[task.setvariable variable=VAULT_IP]$VAULT_IP"

              # Get Token Reviewer JWT
              echo "Fetching Vault SA Token..."
              # Ensure secret exists (created by Vault helm chart/injector usually, or we create one)
              # The 'vault' release creates a ServiceAccount named 'vault'.
              # We need a token for the 'vault' SA or the one defined in auth config.
              # Let's use the default one or one explicitly created for auth delegation.
              # In K8s 1.24+, secrets are not auto-created.

              # Check if secret exists or create/get token
              TOKEN_REVIEWER_JWT=$(kubectl get secret vault-auth-token -n vault -o jsonpath='{.data.token}' 2>/dev/null | base64 -d || true)

              if [ -z "$TOKEN_REVIEWER_JWT" ]; then
                  echo "Creating manual secret for vault-auth-token..."
                  kubectl apply -f - <<EOF
                  apiVersion: v1
                  kind: Secret
                  metadata:
                    name: vault-auth-token
                    namespace: vault
                    annotations:
                      kubernetes.io/service-account.name: vault
                  type: kubernetes.io/service-account-token
              EOF
                  sleep 2
                  TOKEN_REVIEWER_JWT=$(kubectl get secret vault-auth-token -n vault -o jsonpath='{.data.token}' | base64 -d)
              fi

              echo "##vso[task.setvariable variable=TOKEN_REVIEWER_JWT;issecret=true]$TOKEN_REVIEWER_JWT"

            displayName: "Get Vault IP & K8s Token"

          # 4) Run Ansible Playbook to Configure Vault
          - script: |
              set -euo pipefail

              echo "Running Ansible Playbook to configure Vault..."

              # Using the passed variable from previous job (mapped in variables block)
              if [ -z "$(VAULT_ROOT_TOKEN)" ]; then
                  echo "##vso[task.logissue type=error]VAULT_ROOT_TOKEN variable is missing! Initialization failed?"
                  exit 1
              fi

              export VAULT_ADDR="http://$(VAULT_IP):8200"
              export VAULT_TOKEN="$(VAULT_ROOT_TOKEN)"
              export K8S_HOST="$(TF_CLUSTER_NAME)"  # Note: logic in previous files used cluster_endpoint, verify if Ansible expects name or URL

              # Actually, Ansible needs K8S_HOST as URL and CA CERT.
              # Fetched via terraform or kubectl? 
              # Let's get them from Kubeconfig or Terraform

              # Re-fetch specific K8s details if needed by Ansible vars
              export K8S_HOST=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')
              export K8S_CA_CERT=$(kubectl config view --minify --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}' | base64 -d)
              export K8S_OIDC_ISSUER="$(TF_OIDC_ISSUER)"

              export TOKEN_REVIEWER_JWT="$(TOKEN_REVIEWER_JWT)"
              export DB_PASSWORD="$(TF_DB_PASSWORD)"
              export RDS_ENDPOINT="$(TF_RDS_ENDPOINT)"
              export REDIS_ENDPOINT="$(TF_REDIS_ENDPOINT)"
              export AWS_REGION="$(awsRegion)"

              # Debug (exclude secrets)
              echo "VAULT_ADDR=$VAULT_ADDR"
              echo "K8S_HOST=$K8S_HOST"
              echo "RDS_ENDPOINT=$RDS_ENDPOINT"

              ansible-playbook ansible/vault-config.yml
            displayName: "Run Ansible Vault Config"
